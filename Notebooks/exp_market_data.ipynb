{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeeeedb4",
   "metadata": {},
   "source": [
    "## Market Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bffc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, qmc\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yfinance\n",
    "import datetime\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6421fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b30af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11ccf8310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24948433",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'option_chain_with_vix.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_market = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moption_chain_with_vix.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df = df_market.copy()\n\u001b[32m      3\u001b[39m df = df.drop(\u001b[33m'\u001b[39m\u001b[33mVIX\u001b[39m\u001b[33m'\u001b[39m, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Option Pricing using Neural Network/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Option Pricing using Neural Network/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Option Pricing using Neural Network/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Option Pricing using Neural Network/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Option Pricing using Neural Network/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'option_chain_with_vix.csv'"
     ]
    }
   ],
   "source": [
    "df_market = pd.read_csv(\"option_chain_with_vix.csv\")\n",
    "df = df_market.copy()\n",
    "df = df.drop('VIX', axis=1)\n",
    "df = df.rename(columns={\"sigma\" : \"VIX\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380e1f5",
   "metadata": {},
   "source": [
    "#### Loading, Cleaning and Feature Engineering\n",
    "- Fetaure\n",
    "    - `M`= log(S/K): Log moneyness \n",
    "    - `t_ann` = time to maturity annulized \n",
    "    - `sigma` = VIX is chosen as a proxy, if VIX is not available then constant Vol = 0.20 \n",
    "      - IV is avoided to avoid circularity  \n",
    "- Traget \n",
    "    - `y_{c/k}`= `mid`/`Strike` (Normalized Call price by Strike price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check required columns exist\n",
    "req = [\"snapshot_date\", \"t_ann\", \"M\", \"mid\", \"strike\"]\n",
    "\n",
    "# parsing date \n",
    "df[\"snapshot_date\"] = pd.to_datetime(df[\"snapshot_date\"], errors=\"coerce\")\n",
    "df = df[df[\"snapshot_date\"].notna()].copy()\n",
    "\n",
    "# Clean data\n",
    "df = df[np.isfinite(df[[\"t_ann\",\"M\",\"mid\",\"strike\"]]).all(axis=1)].copy()\n",
    "df = df[(df[\"t_ann\"] > 0) & (df[\"strike\"] > 0) & (df[\"mid\"] >= 0)].copy()\n",
    "\n",
    "# Create target: C/K\n",
    "df[\"y_ck\"] = (df[\"mid\"] / df[\"strike\"]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcea50",
   "metadata": {},
   "source": [
    "##### Data Check\n",
    "We enforce basic financial and numerical sanity checks prior to model training. Time-to-maturity (t_ann) is required to be strictly positive to avoid degenerate contracts. All model inputs (M, t_ann, VIX) are constrained to be finite, excluding missing or infinite values that would destabilize optimization. Option strikes are restricted to positive values, and observed mid-prices are constrained to be non-negative, consistent with no-arbitrage bounds. These assertions ensure numerical stability and economic validity of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert \n",
    "assert (df_market[\"t_ann\"] > 0).all()\n",
    "assert np.isfinite(df_market[[\"M\", \"t_ann\", \"sigma\"]]).all().all(), \"NaNs or infs in X\"\n",
    "assert (df_market[\"strike\"] > 0).all(), \"Invalid strikes\"\n",
    "assert (df_market[\"mid\"] >= 0).all(), \"Negative prices\"            \n",
    "  \n",
    "# target variable \n",
    "df_market[\"C/K\"] = df_market[\"mid\"] / df_market[\"strike\"]\n",
    "df_market[\"C_dollar\"] = df_market[\"mid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69280658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_sigma(df):\n",
    "    if \"VIX\" in df.columns and np.isfinite(df[\"VIX\"]).mean() > 0.99:\n",
    "        return \"VIX\"\n",
    "    df[\"sigma_proxy\"] = 0.20\n",
    "    return \"sigma_proxy\"\n",
    "\n",
    "sigma_col = pick_sigma(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def32ff",
   "metadata": {},
   "source": [
    "#### Train:Test Split: Time based split \n",
    "- sorted by dates \n",
    "- first 80% dates for training \n",
    "- last 20% for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cdd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dates: 272 | Train dates: 217 | Test dates: 55\n",
      "Train rows: 980328 | Test rows: 281288\n"
     ]
    }
   ],
   "source": [
    "dates = np.array(sorted(df[\"snapshot_date\"].unique()))\n",
    "if len(dates) < 5:\n",
    "    raise ValueError(f\"Need more unique dates for time split, got {len(dates)}\")\n",
    "\n",
    "\n",
    "# 80:20\n",
    "split = int(0.8 * len(dates))\n",
    "train_dates = set(dates[:split])\n",
    "test_dates  = set(dates[split:])\n",
    "\n",
    "\n",
    "# split base on time \n",
    "train_df = df[df[\"snapshot_date\"].isin(train_dates)].copy()\n",
    "test_df  = df[df[\"snapshot_date\"].isin(test_dates)].copy()\n",
    "\n",
    "print(f\"Unique dates: {len(dates)} | Train dates: {len(train_dates)} | Test dates: {len(test_dates)}\")\n",
    "print(f\"Train rows: {len(train_df)} | Test rows: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a28a36",
   "metadata": {},
   "source": [
    "#### Gaussian weighted loss function calcualtion for the real data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # weights implementation\n",
    "# def gaussian_weights(df, lam=1, beta=0.5, M_col=\"M\", T_col=\"t_ann\", normalize_mean=True):\n",
    "#     M = df[M_col].astype(float).to_numpy()\n",
    "#     T = df[T_col].astype(float).to_numpy()\n",
    "    \n",
    "#     # weights\n",
    "#     w = np.exp(-(M**2) / (2.0 * lam**2) - beta * T).astype(np.float32)\n",
    "#     w = np.clip(w, 1e-4, None)        #  prevents zero-weight underflow\n",
    "#     w = w / (np.mean(w) + 1e-8)\n",
    "    \n",
    "#     # Normalize weights to mean=1\n",
    "#     if normalize_mean:\n",
    "#         w = w / (np.mean(w) + 1e-8)\n",
    "    \n",
    "#     return w\n",
    "\n",
    "def gaussian_weights(\n",
    "    df,\n",
    "    lam=0.4,              # wider ATM band\n",
    "    beta=5.0,             # much softer time decay\n",
    "    M_col=\"M\",\n",
    "    T_col=\"t_ann\",\n",
    "    normalize_mean=True,\n",
    "    w_floor_itm=0.05      # << NEW\n",
    "):\n",
    "    M = df[M_col].to_numpy(float)\n",
    "    T = df[T_col].to_numpy(float)\n",
    "\n",
    "    w = np.exp(-(M**2)/(2*lam**2) - beta*T)\n",
    "\n",
    "    # region-aware floor\n",
    "    itM = M > 0.05\n",
    "    w[itM] = np.maximum(w[itM], w_floor_itm)\n",
    "\n",
    "    w = w.astype(np.float32)\n",
    "    w /= (np.mean(w) + 1e-8)\n",
    "\n",
    "    if normalize_mean:\n",
    "        w /= (np.mean(w) + 1e-8)\n",
    "\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af51e8c1",
   "metadata": {},
   "source": [
    "#### Hyperparameter Lambda and Beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549babfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train weights: min=5.7255e-07, max=2.5315e+00, mean=1.0000, median=0.7238\n"
     ]
    }
   ],
   "source": [
    "LAMBDA = 0.4   # lambda (log-moneyness width) \n",
    "BETA   = 5.0   # beta (time penalty rate)\n",
    "ALPHA = 0.9\n",
    "\n",
    "\n",
    "w_train = gaussian_weights(train_df, \n",
    "                           lam=LAMBDA, \n",
    "                           beta=BETA)\n",
    "w_test  = gaussian_weights(test_df,  \n",
    "                           lam=LAMBDA, \n",
    "                           beta=BETA)\n",
    "\n",
    "\n",
    "# chceck tarin weights\n",
    "print(f\"Train weights: min={w_train.min():.4e}, max={w_train.max():.4e}, mean={w_train.mean():.4f}, median={np.median(w_train):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172f4b4",
   "metadata": {},
   "source": [
    "#### Feature Engineering \n",
    "#### Z-Score Standardization\n",
    "The scale and distribution of the inputs are heterogeous and hence required standardization for numerical stability and gradient scaling. Therefore Z-score scaling has been used with the following properties:\n",
    "- compute the mu and sigma on training data, and freeze it to avoid lookahead bias \n",
    "- apply the same transformation on the test data \n",
    "$$\\hat x_{test} = \\frac{x_{test} - \\mu_{train}}{\\sigma_{train}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"t_ann\", \"M\", sigma_col]  # X=[T, logM, sigma]\n",
    "\n",
    "# Input features \n",
    "X_train = train_df[FEATURES].to_numpy(np.float32)\n",
    "X_test  = test_df[FEATURES].to_numpy(np.float32)\n",
    "\n",
    "# target variables \n",
    "y_train = train_df[\"y_ck\"].to_numpy(np.float32)                          \n",
    "y_test  = test_df[\"y_ck\"].to_numpy(np.float32)\n",
    "\n",
    "# Compute mean/std on TRAIN only\n",
    "mu = X_train.mean(axis=0)                                             \n",
    "sd = X_train.std(axis=0)\n",
    "sd = np.where(sd < 1e-8, 1.0, sd)\n",
    "\n",
    "# Apply to both train and test \n",
    "# the mu and sigma are calulated on the training set only to avoid lookahead bias \n",
    "X_train_z = (X_train - mu) / sd\n",
    "X_test_z  = (X_test  - mu) / sd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a37208",
   "metadata": {},
   "source": [
    "#### DataLoader with weights \n",
    "-  batching the dataset into batches for efficient trainig \n",
    "- using dataloader for bathcing \n",
    "- shuffle=True, training will be shuffled but (only on the training dataset)\n",
    "\n",
    "PyTorch `DataLoader` is a utility class designed to simplify the load and iteration over the datset for training. It has various contraints for the batching, suffling and processing data. \n",
    "- Batching helps to reduce the memory footprint by leveraging parallel processing\n",
    "- shuffling prevents the model to overfit to noise by shuffling the dataset on the learning, provides more stable training and avoid stucking in local minima \n",
    "\n",
    "In our code:\n",
    "we are loading the whole dataset from the disk into ram (since dataset is small), converting it into tensor (it lives on RAM), then we `__getitem__` lazy, from the ram on the index i (all labels at i), this avoid making a copy on the ram for the shuffled data on the RAM. Which is abstracted by the the DataLoader class by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Data loading and batching \n",
    "class OptionDataset(Dataset):\n",
    "    def __init__(self, X, y, w):\n",
    "        # convert into tensor \n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.w = torch.tensor(w, dtype=torch.float32)  # Weights \n",
    "    \n",
    "    # length of data    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    # get each values at index i\n",
    "    def __getitem__(self, i):                                         \n",
    "        return self.X[i], self.y[i], self.w[i]\n",
    "    \n",
    "\n",
    "# batch training \n",
    "BATCH = 2048\n",
    "\n",
    "train_ds = OptionDataset(X_train_z, y_train, w_train)\n",
    "test_ds  = OptionDataset(X_test_z,  y_test,  w_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, drop_last=False)        \n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c29d4f9",
   "metadata": {},
   "source": [
    "#### Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17K param model same as above \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden=(64, 64), dropout=0.0, use_softplus=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden:\n",
    "            layers.append(nn.Linear(d, h))\n",
    "            layers.append(nn.ELU())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            d = h  # update input dimension for next layer\n",
    "\n",
    "        self.body = nn.Sequential(*layers)\n",
    "        self.out = nn.Linear(d, 1)  # d is last hidden size\n",
    "        self.softplus = nn.Softplus() if use_softplus else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        x = self.out(x)\n",
    "        x = self.softplus(x)        # enforces non-negative output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a85be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 1])\n"
     ]
    }
   ],
   "source": [
    "m = MLP(in_dim=3, hidden=(64,64), use_softplus=True)\n",
    "xb = torch.randn(2048, 3)\n",
    "print(m(xb).shape)  # should be torch.Size([2048, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f099347e",
   "metadata": {},
   "source": [
    "##### Loss function design\n",
    "- we are using the same example as we used in the synthetic dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse(pred, y):\n",
    "    return torch.mean((pred - y) ** 2)\n",
    "\n",
    "def loss_wmse(pred, y, w):\n",
    "    # wighted mse formula see equation*\n",
    "    return torch.sum(w * (pred - y) ** 2) / torch.sum(w)\n",
    "\n",
    "# Mixture Loss:  alpha*WMSE + (1-alpha)*MSE\n",
    "def loss_mix(pred, y, w, alpha=0.7):\n",
    "    mse  = torch.mean((pred - y) ** 2)\n",
    "    wmse = torch.sum(w * (pred - y) ** 2) / (torch.sum(w) + 1e-8)\n",
    "    return alpha * wmse + (1.0 - alpha) * mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444beda",
   "metadata": {},
   "source": [
    "#### Training and Testing\n",
    "- Outer Split: Split the data into 80:20 (train:test)\n",
    "- inner split: Split train data into 90:10 (train:val) \n",
    "- keep test data completely out of sample \n",
    "- validation use early stopping and model selection without peeking the test \n",
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052ae1b",
   "metadata": {},
   "source": [
    "##### Helper functions \n",
    "1. inner split \n",
    "2. mask for inner split and validation \n",
    "3. feature selection and numpy extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56b4cbc",
   "metadata": {},
   "source": [
    "#### Temporal Data Partitioning \n",
    "`inner_split_masks`: This function creates a temporal split on the data by sorting the date and hold out the future date for the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c091b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_split_masks(train_df_,\n",
    "                            date_col = \"snapshot_date\", \n",
    "                            frac_train=0.9\n",
    "                            ):\n",
    "    \"\"\"_summary_\n",
    "    Time-based split unique dates in the date column,\n",
    "    prevents look ahead bias by construction \n",
    "\n",
    "    Returns:\n",
    "        inner_mask and val_mask for the time based split for the training dataset \n",
    "    \"\"\"\n",
    "    # assert missing date col\n",
    "    assert date_col in train_df_.columns, \"Missing Date Column\"\n",
    "    \n",
    "    # arrange chronologically and select the dates \n",
    "    dts = np.array(sorted(train_df_[date_col].unique()))\n",
    "    \n",
    "    # cut select the index max of training data, which we will use later for validation, \n",
    "    # this avoid look-ahead bias in the validation set \n",
    "    cut = max(1, int(frac_train * len(dts)))\n",
    "    \n",
    "    # return set for past and future dts for immutable faster lookup later \n",
    "    inner_train_dates = set(dts[:cut])\n",
    "    val_dates = set(dts[cut:])\n",
    "    \n",
    "    # convert it into inner and val mask  \n",
    "    inner_mask = train_df_[date_col].isin(inner_train_dates).to_numpy()\n",
    "    val_mask   = train_df_[date_col].isin(val_dates).to_numpy()\n",
    "\n",
    "    # safe assertion \n",
    "    assert inner_mask.shape == val_mask.shape                                                 # shape check \n",
    "    assert inner_mask.sum() > 0, \"No rows in inner train split\"                               # greater than 0 rows\n",
    "    assert val_mask.sum() > 0, \"No rows in val split\"                                       \n",
    "    assert not np.any(inner_mask & val_mask), \"Overlap between inner train and val!\"          # no overlap for look ahead bias in val\n",
    "\n",
    "    return inner_mask, val_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f608c",
   "metadata": {},
   "source": [
    "#### Data preperation and Data Integrity \n",
    "- `extract_arrays`: extracts the feature and target columns and convert them into np.float32 for later use \n",
    "- `fit_zscore`: Explicitly calls the fit_zscore(X_inner) only on the training set and hence avoid *Data leakage* from the test dataset. For numerical robustness np.where(sd < eps) ensures that the there is 1 SD instead of NaN or Zero  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62679ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Extraction and Numpy conversion\n",
    "def extract_arrays(df_, \n",
    "                   feature_cols,\n",
    "                   y_col=\"y_ck\", \n",
    "                   dtype=np.float32):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df_: training dataFrame \n",
    "        feature_cols: t_ann, M and sigma  \n",
    "        y_col: Strike normalized Call price \n",
    "        dtype: Defaults to np.float32.\n",
    "\n",
    "    Returns:\n",
    "        X, y numpy arrays \n",
    "    \"\"\"\n",
    "\n",
    "# check if column exists in df\n",
    "    assert all(c in df_.columns for c in feature_cols), f\"Missing features: {feature_cols}\"  \n",
    "    assert y_col in df_.columns, f\"Missing target col: {y_col}\"  \n",
    "\n",
    "    X = df_[feature_cols].to_numpy(dtype)\n",
    "    y = df_[y_col].to_numpy(dtype)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# apply z-score for inner traing only \n",
    "def fit_zscore(X, eps=1e-8):   \n",
    "    mu = X.mean(axis=0)\n",
    "    sd = X.std(axis=0)\n",
    "    sd = np.where(sd < eps, 1.0, sd)     # if feature has zero variance -> sd = 0 -> default to 1   \n",
    "    return mu, sd\n",
    "\n",
    "def apply_zscore(X, mu, sd):\n",
    "    return (X - mu) / sd\n",
    "\n",
    "\n",
    "# inner val loader and tensors \n",
    "def make_inner_val_loaders(\n",
    "    train_df_,\n",
    "    feature_cols,\n",
    "    w_train_all,                 # weights aligned with train_df_ rows (same order)\n",
    "    date_col=\"snapshot_date\",\n",
    "    frac_train=0.9,\n",
    "    batch_size=2048  \n",
    "):\n",
    "    \n",
    "    # masks\n",
    "    inner_mask, val_mask = inner_split_masks(train_df_, \n",
    "                                                   date_col=date_col, \n",
    "                                                   frac_train=frac_train)\n",
    "\n",
    "    # arrays\n",
    "    X_all, y_all = extract_arrays(train_df_, \n",
    "                                  feature_cols, \n",
    "                                  y_col=\"y_ck\")\n",
    "\n",
    "    # split\n",
    "    X_inner, y_inner, w_inner = X_all[inner_mask], y_all[inner_mask], w_train_all[inner_mask]\n",
    "    X_val,   y_val,   w_val   = X_all[val_mask],   y_all[val_mask],   w_train_all[val_mask]\n",
    "\n",
    "    # fit scaler on inner-train only - no lookahead into val  \n",
    "    mu, sd = fit_zscore(X_inner)\n",
    "\n",
    "    # the X_val and X_inner z score values are kept seperate \n",
    "    X_inner_z = apply_zscore(X_inner, mu, sd).astype(np.float32)       \n",
    "    X_val_z   = apply_zscore(X_val,   mu, sd).astype(np.float32) \n",
    "\n",
    "    # generator seed\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "    \n",
    "    # datasets/loaders\n",
    "    inner_ds = OptionDataset(X_inner_z, y_inner, w_inner)\n",
    "    inner_loader = DataLoader(inner_ds, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              drop_last=False, \n",
    "                              generator=g)\n",
    "\n",
    "    # val tensors\n",
    "    X_val_t = torch.tensor(X_val_z, dtype=torch.float32, device=DEVICE)\n",
    "    y_val_t = torch.tensor(y_val,   dtype=torch.float32, device=DEVICE)\n",
    "    w_val_t = torch.tensor(w_val,   dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    return inner_loader, (X_val_t, y_val_t, w_val_t), (mu, sd), (inner_mask, val_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3d136",
   "metadata": {},
   "source": [
    "##### Training function for EPOCH and Loss Calcualtions\n",
    "This function implements a single epoch training using opt=ADAM optimizer. During each iteration, loader from DataLoader provides the mini-batches of inputs (xb), targets (yb) and sample weights (wb). All tensor are passed to DEVICE. \n",
    "\n",
    "The objective is selected dynamically using the mode parameter:\n",
    "1. 'mse': Mean squared error, treating all the error samples uniformly \n",
    "2. 'wmse': wighted mean square error with the ephasis on ATM-short dated options\n",
    "3. 'mix': a convex combination of MSE and WMSE, controlled by a mixing coefficient alpha\n",
    "\n",
    "Before backprop, gradients are cleared, setting graients to None. Epoch level loss is accumulated as a **sum of batch loss weighted by batch size** rather than averaging per-batch loss directly. This ensure partial batches are handled correctly and loss represent the true sample level avg loss across epochs. \n",
    "\n",
    "The function returns the avergae loss per observation for the epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# training one EPOCH  \n",
    "def train_one_epoch(model, loader, opt, mode=\"mse\"): \n",
    "    model.train()                                          # set model to training            \n",
    "    total_loss = 0.0                                       # total loss \n",
    "    n_obs = 0                                              # total no of observation in the batch\n",
    "\n",
    "    for xb, yb, wb in loader:                              # chuck training from loader \n",
    "        xb = xb.to(DEVICE)                                     # laoder handles the shuffling of batch data         \n",
    "        yb = yb.to(DEVICE)                                        # handles partial batches \n",
    "        wb = wb.to(DEVICE)\n",
    "\n",
    "        pred = model(xb).squeeze(-1)\n",
    "\n",
    "        if mode == \"mse\":                                     \n",
    "            loss = loss_mse(pred, yb)\n",
    "        elif mode == \"wmse\":\n",
    "            loss = loss_wmse(pred, yb, wb)\n",
    "        elif mode == \"mix\":\n",
    "            loss = loss_mix(pred, yb, wb, alpha=ALPHA)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)                       # Optimization \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        bs = xb.shape[0]                                      # calcualte the batch size              \n",
    "        total_loss += float(loss.item()) * bs                 # total loss = loss * batch size; convert tensor into -> float \n",
    "        n_obs += bs\n",
    "\n",
    "    return total_loss / max(1, n_obs)                          # final loss = total loss / avg sample in epoch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416964ca",
   "metadata": {},
   "source": [
    "##### Loss Evaluation: MSE, WMSE and MIX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function for both methods \n",
    "@torch.no_grad()                                       # no grad for eval \n",
    "def eval_loss(model, \n",
    "              X_t, \n",
    "              y_t, \n",
    "              w_t, \n",
    "              mode=\"mse\"):\n",
    "    model.eval()\n",
    "    pred = model(X_t).squeeze(-1)\n",
    "\n",
    "    if mode == \"mse\":                                  # two models for comparision with different loss function\n",
    "        return float(loss_mse(pred, y_t).item())\n",
    "    elif mode == \"wmse\":                              \n",
    "        return float(loss_wmse(pred, y_t, w_t).item())\n",
    "    elif mode == \"mix\":\n",
    "        return float(loss_mix(pred, y_t, w_t, alpha=ALPHA).item())\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba6e33",
   "metadata": {},
   "source": [
    "##### Model Training and Early Stopping \n",
    "- this function uses the `model`, `inner_loader` (to load the batched data), `tain_one_epoch`, and `eval_loss`\n",
    "- `model_train_ES` function loop over multiple EPOCH to train the model with early stopping, the early stopping condition is checked using the validation loss with a small tolerance to create a buffer for improvement in the model, the best model weights are then saved and loaded using the `state_dict` object (python dict), it returns model and best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with early stopping \n",
    "def model_train_ES(\n",
    "    model,\n",
    "    inner_loader,\n",
    "    val_pack,                 # (X_val_t, y_val_t, w_val_t)\n",
    "    mode=\"mse\",\n",
    "    lr=1e-3,\n",
    "    epochs=100,               \n",
    "    patience=15,\n",
    "    tol=1e-6,\n",
    "    status_print=10\n",
    "):\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)   \n",
    "\n",
    "    X_val_t, y_val_t, w_val_t = val_pack    # unpack\n",
    "  \n",
    "    best_val = float(\"inf\")                 # best validation loss; initialize at inf \n",
    "    best_state = None                       # Model weights when best val was achieved\n",
    "    bad = 0                                 # a counter for epochs without improvement in val \n",
    "\n",
    "    for ep in range(1, epochs + 1):          \n",
    "        # for each epoch complete pass\n",
    "        tr = train_one_epoch(model, \n",
    "                             inner_loader, \n",
    "                             opt, \n",
    "                             mode=mode)\n",
    "        \n",
    "        # for each epoch calculate eval loss \n",
    "        v  = eval_loss(model,                        \n",
    "                       X_val_t, \n",
    "                       y_val_t, \n",
    "                       w_val_t, \n",
    "                       mode=mode)\n",
    "\n",
    "\n",
    "        # Early stopping.                                        # if current loss < best_loss - tolerance\\\n",
    "        if v < best_val - tol:                                     # early stopping if no significant error \n",
    "            best_val = v                                            # update best val \n",
    "            best_state = copy.deepcopy(model.state_dict())          # to save the weights in the dataset\n",
    "            bad = 0                                                   # for each epoch count the bad \n",
    "        else:\n",
    "            bad += 1                                                # increment if no improvelement for the epoch\n",
    "\n",
    "        if ep == 1 or ep % status_print == 0:\n",
    "            print(f\"[{mode.upper()}] ep {ep:3d} | train {tr:.6f} | val {best_val:.6f} | bad {bad}/{patience}\")\n",
    "\n",
    "        # if bad epoch > patience stop \n",
    "        if bad >= patience:\n",
    "            break\n",
    "\n",
    "    # restore the best model from the best epoch \n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a89b8f",
   "metadata": {},
   "source": [
    "#### Test Set Tensor Preparation \n",
    "- Standardization: Test features are standardized using the mean (mu) and standard deviation (sd) computed on the training set only.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee1d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors \n",
    "def make_test_tensors(test_df, \n",
    "                      feature_cols, \n",
    "                      mu, \n",
    "                      sd, \n",
    "                      w_test, \n",
    "                      y_col=\"y_ck\"):\n",
    "    # raw arrays\n",
    "    X_test = test_df[feature_cols].to_numpy(np.float32)\n",
    "    y_test = test_df[y_col].to_numpy(np.float32)\n",
    "\n",
    "    # Standardize using taraing statistics - apply TRAIN-FIT scaler (mu, sd)\n",
    "    X_test_z = ((X_test - mu) / sd).astype(np.float32)\n",
    "\n",
    "    \n",
    "    # create tensors \n",
    "    X_test_t = torch.tensor(X_test_z, \n",
    "                            dtype=torch.float32, \n",
    "                            device=DEVICE)              # to have consistent output after division we convert again to float32\n",
    "    y_test_t = torch.tensor(y_test,   \n",
    "                            dtype=torch.float32, \n",
    "                            device=DEVICE)\n",
    "    w_test_t = torch.tensor(w_test,   \n",
    "                            dtype=torch.float32, \n",
    "                            device=DEVICE)\n",
    "    return X_test_t, y_test_t, w_test_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e823f",
   "metadata": {},
   "source": [
    "#### Metrics and  Evaluation \n",
    "The module below provides a the metrics to compare the three models (MSE, WMSE and MIX objective function) to understand the performace on the MSE, WMSE, RMSE and MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf922ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict  \n",
    "# model eval mode on MSE, WMSE, MAE, RMSE\n",
    "@torch.no_grad()\n",
    "def predict(model, X_t):\n",
    "    model.eval()\n",
    "    return model(X_t).squeeze(-1).detach().cpu().numpy()      # no gradients to numpy array \n",
    "\n",
    "# METRICS \n",
    "# MSE \n",
    "def mse(a, b):\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    return float(np.mean((a - b) **2))\n",
    "\n",
    "# WMSE \n",
    "def wmse(a, b, w):\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    w = np.asarray(w)\n",
    "    return float(np.sum(w * (a - b)**2) / np.sum(w))\n",
    "\n",
    "# Metrics \n",
    "# rmse \n",
    "def rmse(a, b):\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    return float(np.sqrt(np.mean((a - b) ** 2)))                # float gives better precision compared to np.float\n",
    "\n",
    "# mae \n",
    "def mae(a, b):\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    return float(np.mean(np.abs(a - b)))        \n",
    "\n",
    "# eval on the following metrics \n",
    "def eval_on_test(model, X_test_t, y_test_t, w_test_t):\n",
    "    yhat = predict(model, X_test_t)\n",
    "    ytrue = y_test_t.detach().cpu().numpy()\n",
    "\n",
    "    # unwighted results \n",
    "    results = {\n",
    "        \"mse\": mse(yhat, ytrue),\n",
    "        \"rmse\": rmse(yhat, ytrue),\n",
    "        \"mae\": mae(yhat, ytrue),\n",
    "        \"yhat_mean\": float(np.mean(yhat)),\n",
    "        \"y_mean\": float(np.mean(ytrue)),\n",
    "    }\n",
    "    \n",
    "    # weighted result addition \n",
    "    if w_test_t is not None:\n",
    "        w_test = w_test_t.detach().cpu().numpy()\n",
    "        results[\"wmse\"] = wmse(yhat, ytrue, w_test)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec5b83",
   "metadata": {},
   "source": [
    "### Model Experiment: MSE vs WMSE vs MIX Model \n",
    "This is a controlled experiment for comparing only the objective function on the same architecture and same dataset with same initialization. The only difference is the objective function. \n",
    "\n",
    "This block constitutes a clean ablation study where:\n",
    "- architecture and data are held constant,\n",
    "- initialization is identical across models,\n",
    "- training hyperparameters and early stopping rules are identical,\n",
    "- and the only treatment variable is the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53c32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MSE] ep   1 | train 0.010912 | val 0.084984 | bad 0/15\n",
      "[MSE] ep  10 | train 0.000935 | val 0.022316 | bad 0/15\n",
      "[MSE] ep  20 | train 0.000894 | val 0.022316 | bad 10/15\n",
      "[WMSE] ep   1 | train 0.009845 | val 0.017818 | bad 0/15\n",
      "[WMSE] ep  10 | train 0.000146 | val 0.004667 | bad 0/15\n",
      "[WMSE] ep  20 | train 0.000126 | val 0.003524 | bad 0/15\n",
      "[WMSE] ep  30 | train 0.000121 | val 0.003515 | bad 7/15\n",
      "[MIX] ep   1 | train 0.010008 | val 0.026489 | bad 0/15\n",
      "[MIX] ep  10 | train 0.000225 | val 0.007116 | bad 0/15\n",
      "[MIX] ep  20 | train 0.000205 | val 0.005617 | bad 2/15\n",
      "[MIX] ep  30 | train 0.000195 | val 0.005617 | bad 12/15\n",
      "Best val mse: 0.02231566235423088\n",
      "Best val wmse: 0.0035145513247698545\n",
      "Best val mix: 0.005617021583020687\n",
      "TEST MSE model: {'mse': 0.07338245958089828, 'rmse': 0.2708919644355774, 'mae': 0.032291118055582047, 'yhat_mean': 0.3511728346347809, 'y_mean': 0.3792925179004669, 'wmse': 0.01044389232993126}\n",
      "TEST WMSE model: {'mse': 0.08704964816570282, 'rmse': 0.2950417697429657, 'mae': 0.03523220121860504, 'yhat_mean': 0.3530040681362152, 'y_mean': 0.3792925179004669, 'wmse': 0.012351471930742264}\n",
      "TEST MIX model: {'mse': 0.08403103798627853, 'rmse': 0.2898810803890228, 'mae': 0.03350323811173439, 'yhat_mean': 0.35131213068962097, 'y_mean': 0.3792925179004669, 'wmse': 0.011918011121451855}\n"
     ]
    }
   ],
   "source": [
    "# inner/val loaders and scaler \n",
    "inner_loader, val_pack, (mu_in, sd_in), (inner_mask, val_mask) = make_inner_val_loaders(\n",
    "                                                                        train_df,\n",
    "                                                                        feature_cols=FEATURES,\n",
    "                                                                        w_train_all=w_train,\n",
    "                                                                        date_col=\"snapshot_date\",\n",
    "                                                                        frac_train=0.9,\n",
    "                                                                        batch_size=BATCH\n",
    "                                                                    )\n",
    "\n",
    "# initialize models from identical weights - for comparision \n",
    "base = MLP(in_dim=len(FEATURES),                             # create a base state and use for MSE and G-WMSE Model and MIX Model  \n",
    "           hidden=(64,64), \n",
    "           dropout=0.0).to(DEVICE)\n",
    "base_state = copy.deepcopy(base.state_dict())\n",
    "\n",
    "\n",
    "# MSE-MODEL\n",
    "model_mse = MLP(in_dim=len(FEATURES),                 \n",
    "                hidden=(64,64),                             \n",
    "                dropout=0.0).to(DEVICE)\n",
    "model_mse.load_state_dict(base_state)\n",
    "\n",
    "\n",
    "# WMSE-MODEL\n",
    "model_wmse = MLP(in_dim=len(FEATURES), \n",
    "                 hidden=(64,64), \n",
    "                 dropout=0.0).to(DEVICE)\n",
    "model_wmse.load_state_dict(base_state)\n",
    "\n",
    "\n",
    "# MIX-MODEL\n",
    "model_mix = MLP(in_dim=len(FEATURES), \n",
    "                hidden=(64,64), \n",
    "                dropout=0.0).to(DEVICE)\n",
    "model_mix.load_state_dict(base_state)\n",
    "\n",
    "\n",
    "# train all three (same data, same init)\n",
    "# mse loss\n",
    "model_mse,  best_val_mse  = model_train_ES(model_mse,  \n",
    "                                        inner_loader, \n",
    "                                        val_pack, \n",
    "                                        mode=\"mse\",\n",
    "                                        lr=1e-3, \n",
    "                                        epochs=300, \n",
    "                                        patience=15)\n",
    "\n",
    "\n",
    "# wmse loss\n",
    "model_wmse, best_val_wmse = model_train_ES(model_wmse, \n",
    "                                    inner_loader, \n",
    "                                    val_pack, \n",
    "                                    mode=\"wmse\",\n",
    "                                    lr=1e-3, \n",
    "                                    epochs=300, \n",
    "                                    patience=15)\n",
    "\n",
    "# mix loss\n",
    "model_mix, best_val_mix = model_train_ES(\n",
    "    model_mix,\n",
    "    inner_loader,\n",
    "    val_pack,\n",
    "    mode=\"mix\",\n",
    "    lr=1e-3,\n",
    "    epochs=300,\n",
    "    patience=15\n",
    ")\n",
    "\n",
    "print(\"Best val mse:\", best_val_mse)\n",
    "print(\"Best val wmse:\", best_val_wmse)\n",
    "print(\"Best val mix:\", best_val_mix)\n",
    "\n",
    "\n",
    "# build test tensors using the SAME mu/sd (mu_in, sd_in)\n",
    "X_test_t, y_test_t, w_test_t = make_test_tensors(test_df, FEATURES, mu_in, sd_in, w_test, y_col=\"y_ck\")\n",
    "\n",
    "# evaluate on test\n",
    "print(\"TEST MSE model:\",  eval_on_test(model_mse,  X_test_t, y_test_t, w_test_t))\n",
    "print(\"TEST WMSE model:\", eval_on_test(model_wmse, X_test_t, y_test_t, w_test_t))\n",
    "print(\"TEST MIX model:\", eval_on_test(model_mix, X_test_t, y_test_t, w_test_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca5c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (281288, 27)\n"
     ]
    }
   ],
   "source": [
    "# Get predictions (already have this function)\n",
    "@torch.no_grad()\n",
    "def predict(model, X_t):\n",
    "    model.eval()\n",
    "    return model(X_t).squeeze(-1).detach().cpu().numpy()\n",
    "\n",
    "# Predict with all three models\n",
    "pred_mse  = predict(model_mse,  X_test_t)      # mse \n",
    "pred_wmse = predict(model_wmse, X_test_t)       # G-Wmse \n",
    "pred_mix  = predict(model_mix,  X_test_t)        # mix\n",
    "\n",
    "y_true = y_test_t.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# Add to test dataframe for analysis\n",
    "test_df['pred_mse'] = pred_mse\n",
    "test_df['pred_wmse'] = pred_wmse\n",
    "test_df['error_mse'] = np.abs(pred_mse - y_true)\n",
    "test_df['error_wmse'] = np.abs(pred_wmse - y_true)\n",
    "test_df['sq_error_mse'] = (pred_mse - y_true) ** 2\n",
    "test_df['sq_error_wmse'] = (pred_wmse - y_true) ** 2\n",
    "\n",
    "print(f\"Shapes: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749212e4",
   "metadata": {},
   "source": [
    "##### Checks: Negative Option Price\n",
    "Since negative option price is violation of the option pricing, we check the role of `softplus` in the output layer which allows for strict non-negative call option pricing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd9c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE model: 0 negative predictions (0.00%)\n",
      "WMSE model: 0 negative predictions (0.00%)\n",
      "MIX model: 0 negative predictions (0.00%)\n"
     ]
    }
   ],
   "source": [
    "def neg_report(name, preds):\n",
    "    n_neg = int((preds < 0).sum())\n",
    "    print(f\"{name}: {n_neg:,} negative predictions ({100*n_neg/len(preds):.2f}%)\")\n",
    "\n",
    "neg_report(\"MSE model\",  pred_mse)\n",
    "neg_report(\"WMSE model\", pred_wmse)\n",
    "neg_report(\"MIX model\",  pred_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd09e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: preds_test.csv\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "out = test_df.copy()\n",
    "\n",
    "out[\"pred_ck_mse\"]  = pred_mse\n",
    "out[\"pred_ck_wmse\"] = pred_wmse\n",
    "out[\"pred_ck_mix\"]  = pred_mix              # mix\n",
    "\n",
    "# errors\n",
    "out[\"err_mse\"]  = out[\"pred_ck_mse\"]  - y_true\n",
    "out[\"err_wmse\"] = out[\"pred_ck_wmse\"] - y_true\n",
    "out[\"err_mix\"]  = out[\"pred_ck_mix\"]  - y_true   # mix\n",
    "\n",
    "out[\"abs_err_mse\"]  = np.abs(out[\"err_mse\"])\n",
    "out[\"abs_err_wmse\"] = np.abs(out[\"err_wmse\"])\n",
    "out[\"abs_err_mix\"]  = np.abs(out[\"err_mix\"])     # mix\n",
    "\n",
    "out[\"sq_error_mse\"]  = out[\"err_mse\"]**2\n",
    "out[\"sq_error_wmse\"] = out[\"err_wmse\"]**2\n",
    "out[\"sq_error_mix\"]  = out[\"err_mix\"]**2         # mix\n",
    "\n",
    "out.to_csv(\"preds_test.csv\", index=False)\n",
    "print(\"Saved: preds_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test weighted MSE metric:\n",
      "  MSE-model : 0.01044389232993126\n",
      "  WMSE-model: 0.012351471930742264\n",
      "  MIX-model : 0.011918011121451855\n"
     ]
    }
   ],
   "source": [
    "def wmse_metric(y, yhat, w):\n",
    "    y = np.asarray(y); yhat = np.asarray(yhat); w = np.asarray(w)\n",
    "    return float(np.sum(w * (y - yhat)**2) / (np.sum(w) + 1e-12))\n",
    "\n",
    "w_test_raw = gaussian_weights(test_df, lam=LAMBDA, beta=BETA, normalize_mean=False)\n",
    "\n",
    "print(\"\\nTest weighted MSE metric:\")\n",
    "print(\"  MSE-model :\",  wmse_metric(y_true, pred_mse,  w_test_raw))\n",
    "print(\"  WMSE-model:\",  wmse_metric(y_true, pred_wmse, w_test_raw))\n",
    "print(\"  MIX-model :\",  wmse_metric(y_true, pred_mix,  w_test_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f958eb",
   "metadata": {},
   "source": [
    "We analyzes model performance across moneyness regimes, with a specific focus on the at-the-money (ATM) region, which is the most liquid and economically relevant part of the option surface.\n",
    "\n",
    "The thresholds are chosen to:\n",
    "\n",
    "- separate deep out-of-the-money and deep in-the-money tails,\n",
    "- isolate a narrow ATM band around zero where pricing sensitivity (gamma) is highest,\n",
    "- align with common practitioner heuristics rather than arbitrary percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ATM REGION (|M| < 0.05) Result:\n",
      "Samples: 70,193\n",
      "RMSE (MSE):  0.007673\n",
      "RMSE (WMSE): 0.002564  | Improvement vs MSE: +66.6%\n",
      "RMSE (MIX):  0.004197   | Improvement vs MSE: +45.3%\n"
     ]
    }
   ],
   "source": [
    "def categorize_moneyness(M):\n",
    "    if M < -0.5: return \"Deep OTM\"\n",
    "    elif M < -0.05: return \"OTM\"\n",
    "    elif M <= 0.05: return \"ATM\"\n",
    "    elif M <= 0.5: return \"ITM\"\n",
    "    else: return \"Deep ITM\"\n",
    "\n",
    "out[\"moneyness_region\"] = out[\"M\"].apply(categorize_moneyness)\n",
    "out[\"tradeable\"] = (out[\"y_ck\"] >= 0.001) & (out[\"y_ck\"] < 1.0)\n",
    "\n",
    "atm_mask = (out[\"M\"].abs() < 0.05)\n",
    "\n",
    "def atm_report(label, sq_err_col):\n",
    "    rmse_val = float(np.sqrt(out.loc[atm_mask, sq_err_col].mean()))\n",
    "    return rmse_val\n",
    "\n",
    "atm_rmse_mse  = atm_report(\"MSE\",  \"sq_error_mse\")\n",
    "atm_rmse_wmse = atm_report(\"WMSE\", \"sq_error_wmse\")\n",
    "atm_rmse_mix  = atm_report(\"MIX\",  \"sq_error_mix\")  \n",
    "\n",
    "print(\"\\nATM REGION (|M| < 0.05) Result:\")\n",
    "print(f\"Samples: {int(atm_mask.sum()):,}\")\n",
    "print(f\"RMSE (MSE):  {atm_rmse_mse:.6f}\")\n",
    "print(f\"RMSE (WMSE): {atm_rmse_wmse:.6f}  | Improvement vs MSE: {100*(atm_rmse_mse-atm_rmse_wmse)/atm_rmse_mse:+.1f}%\")\n",
    "print(f\"RMSE (MIX):  {atm_rmse_mix:.6f}   | Improvement vs MSE: {100*(atm_rmse_mse-atm_rmse_mix)/atm_rmse_mse:+.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE BY REGION:\n",
      "  Region      n  RMSE (MSE)  RMSE (WMSE)  RMSE (MIX)  WMSE vs MSE %  MIX vs MSE %\n",
      "Deep OTM   7323 0.000249118  0.000255923 0.000287197       -2.73195      -15.2855\n",
      "     OTM  68390  0.00296564   0.00312274  0.00286201       -5.29747       3.49439\n",
      "     ATM  70193  0.00767337   0.00256411  0.00419729        66.5842       45.3005\n",
      "     ITM 101152  0.00801004   0.00788688  0.00762288        1.53763        4.8335\n",
      "Deep ITM  34230    0.776337     0.845648    0.830848       -8.92804      -7.02158\n"
     ]
    }
   ],
   "source": [
    "def compare_by_region(df):\n",
    "    rows = []\n",
    "    for region in [\"Deep OTM\", \"OTM\", \"ATM\", \"ITM\", \"Deep ITM\"]:\n",
    "        mask = (df[\"moneyness_region\"] == region)\n",
    "        n = int(mask.sum())\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        rmse_mse  = float(np.sqrt(df.loc[mask, \"sq_error_mse\"].mean()))\n",
    "        rmse_wmse = float(np.sqrt(df.loc[mask, \"sq_error_wmse\"].mean()))\n",
    "        rmse_mix  = float(np.sqrt(df.loc[mask, \"sq_error_mix\"].mean()))\n",
    "\n",
    "        rows.append({\n",
    "            \"Region\": region,\n",
    "            \"n\": n,\n",
    "            \"RMSE (MSE)\":  rmse_mse,\n",
    "            \"RMSE (WMSE)\": rmse_wmse,\n",
    "            \"RMSE (MIX)\":  rmse_mix,\n",
    "            \"WMSE vs MSE %\": 100.0 * (rmse_mse - rmse_wmse) / (rmse_mse + 1e-12),\n",
    "            \"MIX vs MSE %\":  100.0 * (rmse_mse - rmse_mix)  / (rmse_mse + 1e-12),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"PERFORMANCE BY REGION:\")\n",
    "reg_tab = compare_by_region(out)\n",
    "print(reg_tab.to_string(index=False, float_format=lambda x: f\"{x:.6g}\"))\n",
    "out.to_csv(\"predictions_with_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OVERALL TEST FIT:\n",
      "                 mse     rmse       mae  RMSE_impr_%_vs_MSE  MAE_impr_%_vs_MSE  yhat_mean   y_mean\n",
      "MSE-model  0.0733825 0.270892 0.0322911                   0                  0   0.351173 0.379293\n",
      "WMSE-model 0.0870496 0.295042 0.0352322            -8.91492           -9.10803   0.353004 0.379293\n",
      "MIX-model   0.084031 0.289881 0.0335032            -7.00984           -3.75373   0.351312 0.379293\n"
     ]
    }
   ],
   "source": [
    "def overall_metrics(y, yhat):\n",
    "    y = np.asarray(y); yhat = np.asarray(yhat)\n",
    "    mse  = float(np.mean((y - yhat)**2))\n",
    "    rmse = float(np.sqrt(mse))\n",
    "    mae  = float(np.mean(np.abs(y - yhat)))\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"yhat_mean\": float(np.mean(yhat)), \"y_mean\": float(np.mean(y))}\n",
    "\n",
    "m_mse  = overall_metrics(y_true, pred_mse)\n",
    "m_wmse = overall_metrics(y_true, pred_wmse)\n",
    "m_mix  = overall_metrics(y_true, pred_mix)\n",
    "\n",
    "summary = pd.DataFrame([m_mse, m_wmse, m_mix], index=[\"MSE-model\", \"WMSE-model\", \"MIX-model\"])\n",
    "summary[\"RMSE_impr_%_vs_MSE\"] = 100.0 * (summary.loc[\"MSE-model\",\"rmse\"] - summary[\"rmse\"]) / (summary.loc[\"MSE-model\",\"rmse\"] + 1e-12)\n",
    "summary[\"MAE_impr_%_vs_MSE\"]  = 100.0 * (summary.loc[\"MSE-model\",\"mae\"]  - summary[\"mae\"])  / (summary.loc[\"MSE-model\",\"mae\"]  + 1e-12)\n",
    "\n",
    "print(\"\\nOVERALL TEST FIT:\")\n",
    "print(summary[[\"mse\",\"rmse\",\"mae\",\"RMSE_impr_%_vs_MSE\",\"MAE_impr_%_vs_MSE\",\"yhat_mean\",\"y_mean\"]]\n",
    "      .to_string(float_format=lambda x: f\"{x:.6g}\"))\n",
    "summary.to_csv(\"overall_fit_3way.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9f4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x420 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.5, 4.2))\n",
    "\n",
    "plt.scatter(out[\"M\"], out[\"err_mse\"],  s=6, alpha=0.22, label=\"MSE\")\n",
    "plt.scatter(out[\"M\"], out[\"err_wmse\"], s=6, alpha=0.22, label=\"WMSE\")\n",
    "plt.scatter(out[\"M\"], out[\"err_mix\"],  s=6, alpha=0.22, label=f\"MIX (={ALPHA})\")\n",
    "\n",
    "plt.axhline(0, color=\"k\", lw=1)\n",
    "plt.axvline(0, color=\"k\", lw=1)\n",
    "\n",
    "plt.xlabel(\"Log-Moneyness M = log(S/K)\")\n",
    "plt.ylabel(\"Prediction Error (C/K)\")\n",
    "plt.title(\"Prediction Error vs Log-Moneyness (Test Set)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baede444",
   "metadata": {},
   "source": [
    "### Model Robustness Check \n",
    "no-arb diagnostic is checked on the test dataset, thus out of sample check. **This only include the tradable universe** which is T > 0.05 years, ultra-short dated options are highly sensetive to marketmicrostucture noise, wide bid-ask spread and discontinious pay-off behaviour near expiry. The stratification is done based on the moneyness where liquid universe is (M <= 0.2) which includes out-of-money, at-the-money and slightly in-the-money options, the deep-in-the-money options M (Log (S/K)) > 0.2 ~ 1.22 or 22% ITM  where the intrincic value dominates. \n",
    "\n",
    "#### No arb constrain \n",
    "For european call option, no-arb requires the option price to satisfy the lower bound \n",
    "\n",
    "$$C \\geq max(S - K^{-rt}, 0)$$\n",
    "\n",
    "meaning the option must be worth atleast its discounted intrinsic value, otherwise, a static arb opportunity exist. Prices are evaluated in normalized in C/K form as above. \n",
    "\n",
    "A lower-bound violation is recorded when the predicted normalized price falls below the theoretical bound by more than a numerical tolerance eps = 0.001, corresponding to $0.10 per $100 strike.This tolerance accounts for floating-point precision and is well within typical bid-ask spreads for SPY options. Market mid-prices are evaluated against the same no-arbitrage criterion and serve as a baseline. Due to **discretization** i.e. there can be small violation arising due to tick-size and use of mid quotes rather than executable price. Also microstructure effects (stale quotes, bid-ask spread due to liquidity), even observed market prices may exhibit occasional bound violations, providing a realistic benchmark for model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c887a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tradeable options: 209055\n",
      "Liquid (M  0.2): 141659\n",
      "Deep ITM (M > 0.2): 67396\n"
     ]
    }
   ],
   "source": [
    "#  tradable uni\n",
    "# Tradeable options (exclude ultra-short maturity ~18 days)\n",
    "tradeable = out[out[\"t_ann\"] > 0.05].copy()\n",
    "\n",
    "liquid   = tradeable[tradeable[\"M\"] <= 0.2].copy()\n",
    "deep_itm = tradeable[tradeable[\"M\"] > 0.2].copy()\n",
    "\n",
    "print(f\"Tradeable options: {len(tradeable)}\")\n",
    "print(f\"Liquid (M  0.2): {len(liquid)}\")\n",
    "print(f\"Deep ITM (M > 0.2): {len(deep_itm)}\")\n",
    "\n",
    "# normalized bound \n",
    "def lower_bound_normalized(df, r=0.035):\n",
    "    S_over_K = np.exp(df[\"M\"].values)                          # European call lower bound (normalized):\n",
    "    discount = np.exp(-r * df[\"t_ann\"].values)                      # C/K  max(S/K - e^{-rT}, 0)\n",
    "    return np.maximum(S_over_K - discount, 0.0)                         # assuming 0.035 risk free interest rate \n",
    "                                                                \n",
    "lb_liquid = lower_bound_normalized(liquid)\n",
    "lb_deep   = lower_bound_normalized(deep_itm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3af943",
   "metadata": {},
   "source": [
    "**70% option in the tradable universe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0483852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        N  Violations (%)    MAE ($)          Universe   Model\n",
      "0  141659        0.205423   0.000000    Liquid (M0.2)  Market\n",
      "1  141659        6.523412   0.406994    Liquid (M0.2)     MSE\n",
      "2  141659        0.000000   0.214007    Liquid (M0.2)    WMSE\n",
      "3  141659        0.000000   0.235868    Liquid (M0.2)     MIX\n",
      "4   67396       40.735355   0.000000  Deep ITM (M>0.2)  Market\n",
      "5   67396       54.805923  11.527567  Deep ITM (M>0.2)     MSE\n",
      "6   67396       15.929729  13.518737  Deep ITM (M>0.2)    WMSE\n",
      "7   67396       23.982135  12.830585  Deep ITM (M>0.2)     MIX\n"
     ]
    }
   ],
   "source": [
    "# viloation\n",
    "TOL = 0.001  # $0.10 per $100 strike\n",
    "\n",
    "def violation_stats(df, preds, lower_bound):\n",
    "    viol = preds < (lower_bound - TOL)\n",
    "    return {\n",
    "        \"N\": len(preds),\n",
    "        \"Violations (%)\": 100 * viol.mean(),\n",
    "        \"MAE ($)\": 100 * np.mean(np.abs(preds - df[\"y_ck\"].values))\n",
    "    }\n",
    "\n",
    "\n",
    "# results \n",
    "models = [\n",
    "    (\"Market\", \"y_ck\"),\n",
    "    (\"MSE\",    \"pred_ck_mse\"),\n",
    "    (\"WMSE\",   \"pred_ck_wmse\"),\n",
    "    (\"MIX\",    \"pred_ck_mix\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Liquid universe\n",
    "for name, col in models:\n",
    "    stats = violation_stats(liquid, liquid[col].values, lb_liquid)\n",
    "    stats.update({\"Universe\": \"Liquid (M0.2)\", \"Model\": name})\n",
    "    results.append(stats)\n",
    "\n",
    "# Deep ITM universe\n",
    "for name, col in models:\n",
    "    stats = violation_stats(deep_itm, deep_itm[col].values, lb_deep)\n",
    "    stats.update({\"Universe\": \"Deep ITM (M>0.2)\", \"Model\": name})\n",
    "    results.append(stats)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ceacf",
   "metadata": {},
   "source": [
    "### Summary \n",
    "We evaluate the no-arb and MAE on the out of sample data. The analysis focuses on liquid call options $T > 0.05$ & $\\, M \\leq 0.2$ which consist of 70% of the test sample contracts. The MSE model violates the European call option lower bound by ~9%, whereas the proposed WMSE and Hybrid MIX model resulted into zero no-arb violation for the liquid options. \n",
    "\n",
    "However, in the deep-ITM (M>0.2) (where also model performance drops significantly -13% when WMSE compared to MSE and -11% for MIX compared to MSE), but there are 5% market violation of the lower bound rule suggesting discretization and market microstructure noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask-based violation rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "# violations disappear at the ask\n",
    "viol_ask = liquid[\"ask\"] < (lb_liquid - TOL)\n",
    "print(\"Ask-based violation rate:\", viol_ask.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
